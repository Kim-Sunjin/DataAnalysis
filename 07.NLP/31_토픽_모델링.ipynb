{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 토픽 모델링-LDA"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\r\n",
    "news = fetch_20newsgroups(subset='all', random_state=2021,\r\n",
    "    remove=('header','footers','quotes'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "df = pd.DataFrame({'article':news.data})\r\n",
    "df.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(18846, 1)"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# 특수문자 제거\r\n",
    "df['article'] = df.article.str.replace('[^A-Za-z]', ' ')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-4-885fc466615d>:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['article'] = df.article.str.replace('[^A-Za-z]', ' ')\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# 소문자로 변환하고 길이가 3 이하인 단어 제거\r\n",
    "df['article'] = df.article.apply(lambda x: ' '.join(w.lower() for w in x.split() if len(w) > 3))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "df.article[0][:100]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'from dagibbs quantum david gibbs subject countersteering sans hands organization software systems li'"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## NLTK를 통해서 단어 토큰화"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "import nltk"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "from nltk.corpus import stopwords\r\n",
    "stop_words = stopwords.words('english')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "tokenized_doc = df.article.apply(lambda x: [w for w in x.split() if w not in stop_words])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "tokenized_doc[:5]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    [dagibbs, quantum, david, gibbs, subject, coun...\n",
       "1    [kehoe, netcom, thomas, david, kehoe, subject,...\n",
       "2    [rexlex, fnal, fnal, subject, assurance, hell,...\n",
       "3    [scss, mark, riordan, subject, list, large, in...\n",
       "4    [adam, stratus, mark, adam, subject, space, fo...\n",
       "Name: article, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 정수 인코딩과 단어 접합 만들기 - gensim"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "!pip install gensim"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.1.0-cp38-cp38-win_amd64.whl (24.0 MB)\n",
      "Collecting smart-open>=1.8.1\n",
      "  Downloading smart_open-5.2.1-py3-none-any.whl (58 kB)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\igksj\\anaconda3\\lib\\site-packages (from gensim) (1.6.2)\n",
      "Collecting Cython==0.29.23\n",
      "  Downloading Cython-0.29.23-cp38-cp38-win_amd64.whl (1.7 MB)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\igksj\\anaconda3\\lib\\site-packages (from gensim) (1.20.3)\n",
      "Installing collected packages: smart-open, Cython, gensim\n",
      "  Attempting uninstall: Cython\n",
      "    Found existing installation: Cython 0.29.24\n",
      "    Uninstalling Cython-0.29.24:\n",
      "      Successfully uninstalled Cython-0.29.24\n",
      "Successfully installed Cython-0.29.23 gensim-4.1.0 smart-open-5.2.1\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "from gensim import corpora\r\n",
    "dictionary = corpora.Dictionary(tokenized_doc)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in tokenized_doc]\r\n",
    "print(corpus[0])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 2), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 2), (16, 1), (17, 1), (18, 2), (19, 1), (20, 1), (21, 1), (22, 2), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1)]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "dictionary[0], dictionary[1], dictionary[2], dictionary[3]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('answer', 'basically', 'bicycle', 'bike')"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## LDA 모델 훈련시키기"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "from gensim.models.ldamodel import LdaModel\r\n",
    "NUM_TOPICS = 20"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "ldamodel = LdaModel(\r\n",
    "    corpus,num_topics=NUM_TOPICS,\r\n",
    "    id2word=dictionary,passes=20\r\n",
    ")\r\n",
    "topics = ldamodel.print_topics(num_topics=4)\r\n",
    "for topic in topics:\r\n",
    "    print(topic)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1, '0.019*\"georgia\" + 0.018*\"buffalo\" + 0.016*\"gatech\" + 0.016*\"ncsu\" + 0.012*\"prism\" + 0.010*\"mask\" + 0.010*\"sharks\" + 0.009*\"books\" + 0.009*\"doug\" + 0.009*\"chinese\"')\n",
      "(8, '0.025*\"space\" + 0.015*\"nasa\" + 0.006*\"power\" + 0.005*\"data\" + 0.005*\"system\" + 0.005*\"earth\" + 0.005*\"mission\" + 0.005*\"shuttle\" + 0.004*\"launch\" + 0.004*\"moon\"')\n",
      "(4, '0.026*\"would\" + 0.018*\"think\" + 0.015*\"know\" + 0.015*\"like\" + 0.013*\"people\" + 0.013*\"lines\" + 0.013*\"subject\" + 0.012*\"organization\" + 0.010*\"could\" + 0.010*\"good\"')\n",
      "(10, '0.021*\"scsi\" + 0.020*\"myers\" + 0.015*\"arizona\" + 0.013*\"ground\" + 0.012*\"wire\" + 0.012*\"weaver\" + 0.011*\"rushdie\" + 0.011*\"harris\" + 0.007*\"randy\" + 0.007*\"nmsu\"')\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 훈련 결과 시각화"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "!pip install pyLDAvis==2.1.2 > /dev/null"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "������ ��θ� ã�� �� �����ϴ�.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "import pyLDAvis.gensim\r\n",
    "pyLDAvis.enable_notebook()\r\n",
    "vis = pyLDAvis.gensim.prepare(ldamodel, corpus, dictionary)\r\n",
    "pyLDAvis.display(vis)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValidationError",
     "evalue": "\n * Not all rows (distributions) in topic_term_dists sum to 1.",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-13df265e3ec4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgensim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_notebook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mvis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mldamodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyLDAvis\\gensim.py\u001b[0m in \u001b[0;36mprepare\u001b[1;34m(topic_model, corpus, dictionary, doc_topic_dist, **kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m     \"\"\"\n\u001b[0;32m    118\u001b[0m     \u001b[0mopts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_extract_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtopic_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdoc_topic_dist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mvis_prepare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mopts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyLDAvis\\_prepare.py\u001b[0m in \u001b[0;36mprepare\u001b[1;34m(topic_term_dists, doc_topic_dists, doc_lengths, vocab, term_frequency, R, lambda_step, mds, n_jobs, plot_opts, sort_topics)\u001b[0m\n\u001b[0;32m    372\u001b[0m    \u001b[0mdoc_lengths\u001b[0m      \u001b[1;33m=\u001b[0m \u001b[0m_series_with_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc_lengths\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'doc_length'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    373\u001b[0m    \u001b[0mvocab\u001b[0m            \u001b[1;33m=\u001b[0m \u001b[0m_series_with_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'vocab'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 374\u001b[1;33m    \u001b[0m_input_validate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtopic_term_dists\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdoc_topic_dists\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdoc_lengths\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mterm_frequency\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    375\u001b[0m    \u001b[0mR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyLDAvis\\_prepare.py\u001b[0m in \u001b[0;36m_input_validate\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m     63\u001b[0m    \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_input_check\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m    \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mValidationError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'\\n'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m' * '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValidationError\u001b[0m: \n * Not all rows (distributions) in topic_term_dists sum to 1."
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "acbbfebbbdf654efa85aa18169a14b54796a806b8c18a3c243660030e08aa454"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}